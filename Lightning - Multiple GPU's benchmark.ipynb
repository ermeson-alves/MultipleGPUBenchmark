{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d326402-0c73-449f-b2e6-30db0c15a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import lightning as L\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision.transforms import v2\n",
    "from torch import nn, optim\n",
    "from torchmetrics import MetricCollection \n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from torchmetrics.classification import Accuracy, Recall, Precision, F1Score, Specificity, ConfusionMatrix, ROC, AUROC\n",
    "import time\n",
    "from colorama import Fore, Back, Style\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_float32_matmul_precision('high')\n",
    "\n",
    "lr=1e-3\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "ticklabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "EPOCHS = 1\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 32\n",
    "CHECKPOINTS_DIR = Path('./multiplegpus_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64eeb92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_metrics = MetricCollection({\n",
    "    'acc': Accuracy('multiclass', num_classes=NUM_CLASSES),\n",
    "    'acc_per_class': Accuracy('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    'recall': Recall('multiclass', num_classes=NUM_CLASSES),\n",
    "    'recall_per_class': Recall('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    'precision': Precision('multiclass', num_classes=NUM_CLASSES),\n",
    "    'precision_per_class': Precision('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    'f1': F1Score('multiclass', num_classes=NUM_CLASSES),\n",
    "    'f1_per_class': F1Score('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    'specificity': Specificity('multiclass', num_classes=NUM_CLASSES),\n",
    "    'specificity_per_class': Specificity('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    # 'auroc': AUROC('multiclass', num_classes=NUM_CLASSES),\n",
    "    # 'auroc_per_class': AUROC('multiclass', num_classes=NUM_CLASSES, average=None),\n",
    "    # 'roccurve_to_plot': ROC('multiclass', num_classes=NUM_CLASSES),\n",
    "    'cm-to-plot': ConfusionMatrix('multiclass', num_classes=NUM_CLASSES)\n",
    "})\n",
    "\n",
    "roccurve = ROC('multiclass', num_classes=NUM_CLASSES)\n",
    "aucroc = AUROC('multiclass', num_classes=NUM_CLASSES)\n",
    "\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationModule(L.LightningModule):\n",
    "    def __init__(self, pretrained_model, loss_function, optimizer):\n",
    "        super().__init__()\n",
    "        self.model = pretrained_model\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_module = loss_function\n",
    "        self.test_step_outputs = []\n",
    "        self.training_step_outputs = []\n",
    "        self.metrics_train = multiclass_metrics.clone(prefix='train-')\n",
    "        self.metrics_test = multiclass_metrics.clone(prefix='test-')\n",
    "        \n",
    "    \n",
    "    def shared_step(self, batch, stage):\n",
    "        inputs, classes = batch\n",
    "        preds = self.model(inputs)\n",
    "        loss = self.loss_module(preds, classes)\n",
    "                \n",
    "        outputs = {\n",
    "            \"loss\": loss,\n",
    "            \"labels\": classes,\n",
    "            \"preds\": preds,\n",
    "        }\n",
    "        if stage == 'train':\n",
    "            self.training_step_outputs.append(outputs)\n",
    "        return outputs\n",
    "\n",
    "\n",
    "    def shared_epoch_end(self, outputs, stage):\n",
    "        labels = torch.cat([x[\"labels\"] for x in outputs])\n",
    "        preds_prob = torch.cat([x[\"preds\"] for x in outputs])\n",
    "        preds = torch.max(preds_prob, dim=1).indices\n",
    "\n",
    "        self.loss_ = self.loss_module(preds_prob, labels)\n",
    "\n",
    "        \n",
    "        if stage == 'test':\n",
    "            tensorboard = self.logger.experiment\n",
    "            metrics = self.metrics_test(preds, labels)\n",
    "            metrics['test-loss'] = self.loss_\n",
    "            \n",
    "            # confusion matrix\n",
    "            fig, ax = plt.subplots()\n",
    "            cm = metrics['test-cm-to-plot']\n",
    "            sns.heatmap(cm.cpu().numpy(), annot=True, cmap=sns.color_palette(\"mako\", as_cmap=True).reversed(), xticklabels=ticklabels,\n",
    "                        yticklabels=ticklabels, ax=ax, fmt='d')\n",
    "            plt.ylabel('True Labels')\n",
    "            plt.xlabel('Predict')\n",
    "            plt.savefig(f'{CHECKPOINTS_DIR}/figs/fig_cm.png')\n",
    "            plt.show()\n",
    "            tensorboard.add_figure(f'plot-Confusion matrix (test)', fig)\n",
    "            \n",
    "            \n",
    "            # roc curve\n",
    "            metrics['test-aucroc'] = aucroc(preds_prob, labels)\n",
    "            metrics['test-roccurve-to-plot'] = roccurve(preds_prob, labels)\n",
    "            fig_, ax_ = roccurve.plot(metrics['test-roccurve-to-plot'], score=True)  \n",
    "            fig_.savefig(f'{CHECKPOINTS_DIR}/figs/fig_ROC.png')\n",
    "            tensorboard.add_figure(f'plot-ROC curve (test)', fig_)\n",
    "        else:\n",
    "            metrics = self.metrics_train(preds, labels)\n",
    "            metrics['train-loss'] = self.loss_\n",
    "            metrics['train-aucroc'] = aucroc(preds_prob, labels)\n",
    "            metrics['train-roccurve-to-plot'] = roccurve(preds_prob, labels)\n",
    "\n",
    "        global_metrics = {key: value for key, value in metrics.items() if not '_' in key and not 'to' in key}\n",
    "        self.log_dict(global_metrics, prog_bar=True)\n",
    "        if NUM_CLASSES>2:\n",
    "            metrics_per_class = {key: value for key, value in metrics.items() \\\n",
    "                                 if '_' in key and not 'to' in key}\n",
    "            # CONFIGURAR O LOG DE METRICAS POR CLASSE\n",
    "\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.shared_step(batch, \"train\")\n",
    "\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        outputs = self.training_step_outputs.copy()\n",
    "        self.training_step_outputs.clear()\n",
    "        return self.shared_epoch_end(outputs,\"train\") \n",
    "\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self.test_step_outputs.append(self.shared_step(batch, \"test\"))\n",
    "        return self.shared_step(batch, \"test\")  \n",
    "\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        return self.shared_epoch_end(self.test_step_outputs, \"test\")\n",
    "\n",
    "\n",
    "    def on_test_end(self):\n",
    "        self.test_step_outputs.clear()\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return self.optimizer(self.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054d8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer learning (fine tuning):\n",
    "# Instanciação VGG16_BN\n",
    "weights = models.VGG16_BN_Weights.DEFAULT # melhores pesos até o momento\n",
    "vgg16 = models.vgg16_bn(weights=weights)\n",
    "# transformações específicas da rede\n",
    "vgg16_preprocess = weights.transforms()\n",
    "# modificando a camada de classificação\n",
    "num_ftrs = vgg16.classifier[-1].in_features\n",
    "vgg16.classifier[-1] = nn.Linear(num_ftrs, 10)\n",
    "vgg16.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa1e4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.RandomHorizontalFlip(),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    'test': v2.Compose([\n",
    "        v2.ToImage(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "        v2.Resize((224, 224)),\n",
    "        v2.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "        ]),\n",
    "    }\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=True, transform=data_transforms['train'], download=True)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./CIFAR10', train=False, transform=data_transforms['test'], download=True)\n",
    "\n",
    "class_names = train_dataset.classes\n",
    "\n",
    "# Definição dos dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                train_dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=True,\n",
    "                num_workers=15) # AVALIAR\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=BATCH_SIZE,\n",
    "                shuffle=False,\n",
    "                num_workers=15) # AVALIAR\n",
    "\n",
    "# plot\n",
    "# print('###  PLOT - EXAMPLE  ###')\n",
    "# inputs, classes = next(iter(trainloader))\n",
    "# out_test = torchvision.utils.make_grid(inputs)\n",
    "# imshow(out_test, title=[class_names[x] for x in classes])\n",
    "\n",
    "\n",
    "model = vgg16\n",
    "logger = TensorBoardLogger('multiplegpus_logs')\n",
    "# DEBUG:\n",
    "# trainer = L.Trainer(fast_dev_run=8) # a execução do trainer se limitará a fast_dev_run batchs\n",
    "trainer = L.Trainer(accelerator='gpu', max_epochs=EPOCHS, logger=logger)\n",
    "\n",
    "\n",
    "# treino\n",
    "star_train = time.time()\n",
    "lighting_model = ClassificationModule(model, loss_function, torch.optim.Adam)\n",
    "trainer.fit(model=lighting_model, train_dataloaders=trainloader)\n",
    "end_train = time.time()\n",
    "print(Fore.GREEN + f'TEMPO DE TREINAMENTO: {end_train - star_train} s')\n",
    "\n",
    "# teste \n",
    "star_test = time.time()\n",
    "trainer.test(model=lighting_model, dataloaders=testloader)\n",
    "end_test = time.time()\n",
    "print(Fore.GREEN + f'TEMPO DE TESTE: {end_test - star_test} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea880fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18b0cf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
